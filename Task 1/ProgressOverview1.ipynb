{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "507a17b7-4c45-4200-a550-637744909e56",
   "metadata": {},
   "source": [
    "Progress report as on 28/9/25 as mentioned in meeting verbally:\n",
    "1. Learnt about linear regresson.\n",
    "2. Learnt about line of best fit and sum of squared residuals.\n",
    "3. Had some knowledge about python beforehand also watched a ten minute refresher on it. Did not pay much attention to the syntax and thought I would learn it along the way or refer to resources if I ran into the problem. \n",
    "4. Thought I would play two nested loops and try out many possible combinations of m and c and the one which gave the least sum of square residuals would choose that one (was only thinking in terms of linear regression until now, hadn't viewed the boston data set). Quickly scratched the idea as there was no guarantee the optimum value of m and c would be in the range I had taken and even then it would take too much time, didn't really feel like the right way.\n",
    "5. Learnt that least value is found by differentiaton of sum of squared residuals.\n",
    "6. Thought there would be a python library to do differentiation and started learning numpy and pandas.\n",
    "7. As I came towards the end of the tutorial realised you can't do differentiation with these libraries. Looked for other libraries but again realised it wasn't the right way.\n",
    "8. Tried to manually differnetiate on paper and got a formula for m and c but again thought this wasn't machine learning.\n",
    "9. Knowing no other way just started reading articles on linear regression by programming and came across the term gradient descent.\n",
    "10. Gradient descent and mean squared error were mentioned in pdf as well but I had thought I would pay attention to it later.\n",
    "11. Read about gradient descent on geekforgeeks and finally realised how to go about it.\n",
    "12. Finally viewed boston data set and saw it was multiple regression. Initally tried to do with loops but then realised had to use numpy, pandas properties to go about it\n",
    "13. Revised numpy, pandas a bit and decided to refer to whatever was required from the video resources.\n",
    "14. Derived formula for partial differential manually and implemented that in code.\n",
    "15. Finally after alot of trial and error due to unfamiliarty with numpy, pandas wrote the code for linear regression.\n",
    "16. Still did not work because of overflow error.\n",
    "17. Normalised the values and also divided the change in w and b by the number of data points. Basically used mean square error instead of square error. Also changed the values of w and b to that of original data set using formula derived in copy. The code for linear regression worked. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
