{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ff3bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57da08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepWeedsDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.img_dir}/{self.data.iloc[idx, 0]}\"\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.data.iloc[idx, 1])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61f7335",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65960303",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DeepWeedsDataset(\n",
    "    csv_file=\"labels/labels.csv\",\n",
    "    img_dir=\"images\",\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = DeepWeedsDataset(\n",
    "    csv_file=\"labels/test_subset1.csv\",\n",
    "    img_dir=\"images\",\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(train_dataset.data.iloc[:,1].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72fc9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef7dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet18(num_classes, partial=True):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    if partial:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e821cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with partial fine-tuning\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\HP/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.0744\n",
      "Epoch 2: Loss = 0.8580\n",
      "Epoch 3: Loss = 0.8070\n",
      "Epoch 4: Loss = 0.7857\n",
      "Epoch 5: Loss = 0.7763\n",
      "\n",
      "Training with full fine-tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.8654\n",
      "Epoch 2: Loss = 0.5837\n",
      "Epoch 3: Loss = 0.4660\n",
      "Epoch 4: Loss = 0.4047\n",
      "Epoch 5: Loss = 0.3639\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for mode in [\"partial\", \"full\"]:\n",
    "    print(f\"\\nTraining with {mode} fine-tuning\")\n",
    "\n",
    "    model = get_resnet18(num_classes, partial=(mode==\"partial\"))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss:.4f}\")\n",
    "\n",
    "    y_true, y_pred = evaluate(model, test_loader)\n",
    "\n",
    "    results[mode] = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, average=\"weighted\"),\n",
    "        \"recall\": recall_score(y_true, y_pred, average=\"weighted\"),\n",
    "        \"f1\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
    "        \"cm\": confusion_matrix(y_true, y_pred)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3446bd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PARTIAL FINE-TUNING\n",
      "accuracy: 0.7585\n",
      "precision: 0.7617\n",
      "recall: 0.7585\n",
      "f1: 0.7499\n",
      "\n",
      "FULL FINE-TUNING\n",
      "accuracy: 0.9047\n",
      "precision: 0.9079\n",
      "recall: 0.9047\n",
      "f1: 0.9019\n"
     ]
    }
   ],
   "source": [
    "for mode, metrics in results.items():\n",
    "    print(f\"\\n{mode.upper()} FINE-TUNING\")\n",
    "    for k,v in metrics.items():\n",
    "        if k != \"cm\":\n",
    "            print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d32d1a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PARTIAL FINE-TUNING\n",
      "accuracy: 0.7585\n",
      "precision: 0.7617\n",
      "recall: 0.7585\n",
      "f1: 0.7499\n",
      "\n",
      "FULL FINE-TUNING\n",
      "accuracy: 0.9047\n",
      "precision: 0.9079\n",
      "recall: 0.9047\n",
      "f1: 0.9019\n"
     ]
    }
   ],
   "source": [
    "for mode, metrics in results.items():\n",
    "    print(f\"\\n{mode.upper()} FINE-TUNING\")\n",
    "    for k,v in metrics.items():\n",
    "        if k != \"cm\":\n",
    "            print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb42a5fe",
   "metadata": {},
   "source": [
    "### Model Choice\n",
    "ResNet-18 was chosen for the DeepWeeds dataset because weed classification involves complex natural images with variations in background, lighting, and plant structure. The residual architecture allows the model to learn strong spatial and texture-based features while maintaining stable training. ResNet-18 provides a good balance between performance and computational efficiency, making it suitable for handling outdoor images without requiring very deep networks. Transfer learning from ImageNet further improves generalization on plant images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
