{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b783a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e656a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb891b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749ea3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1153792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4451b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ed84342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = self.pool(F.relu(self.conv3(x)))  \n",
    "\n",
    "        x = x.view(x.size(0), -1)            \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)                   \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7493efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a21bb18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a01f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6da62006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.5090, Val Acc=0.8686\n",
      "Epoch 2: Loss=0.3079, Val Acc=0.8928\n",
      "Epoch 3: Loss=0.2597, Val Acc=0.9008\n",
      "Epoch 4: Loss=0.2282, Val Acc=0.9061\n",
      "Epoch 5: Loss=0.2032, Val Acc=0.9074\n",
      "Epoch 6: Loss=0.1808, Val Acc=0.9067\n",
      "Epoch 7: Loss=0.1616, Val Acc=0.9079\n",
      "Epoch 8: Loss=0.1432, Val Acc=0.9143\n",
      "Epoch 9: Loss=0.1267, Val Acc=0.9130\n",
      "Epoch 10: Loss=0.1130, Val Acc=0.9113\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader)\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss={train_loss:.4f}, Val Acc={val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d172ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b46fcea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      1000\n",
      "           1       0.99      0.98      0.99      1000\n",
      "           2       0.90      0.82      0.86      1000\n",
      "           3       0.92      0.92      0.92      1000\n",
      "           4       0.88      0.85      0.86      1000\n",
      "           5       0.97      0.99      0.98      1000\n",
      "           6       0.74      0.76      0.75      1000\n",
      "           7       0.97      0.95      0.96      1000\n",
      "           8       0.96      0.99      0.98      1000\n",
      "           9       0.96      0.97      0.97      1000\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "[[886   0  10  10   4   2  76   0  12   0]\n",
      " [  3 981   0  11   3   0   1   0   1   0]\n",
      " [ 28   2 825  10  51   0  81   0   3   0]\n",
      " [ 26   3   7 917  14   0  28   0   4   1]\n",
      " [  2   2  38  32 848   2  73   0   3   0]\n",
      " [  0   0   0   0   0 989   0   6   0   5]\n",
      " [129   1  36  19  45   1 755   0  14   0]\n",
      " [  0   0   0   0   0  21   0 946   1  32]\n",
      " [  3   1   0   1   1   1   2   1 990   0]\n",
      " [  1   0   0   0   0   8   0  21   0 970]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
