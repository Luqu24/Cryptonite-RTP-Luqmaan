{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50af4f90-e517-4908-a604-b1fe579a5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81728016-15c2-4e8d-997a-55b45a5f325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y, n_h):\n",
    "    n_x = X.shape[0] # number of input features\n",
    "    n_y = Y.shape[0]\n",
    "\n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db188f57-cb20-46a4-b07f-f1742351f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    W1 = np.random.randn(n_h, n_x)\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y, n_h)\n",
    "    b2 = np.zeros((n_y,1))\n",
    "\n",
    "    parameters = {\"W1\" : W1,\n",
    "                  \"b1\" : b1,\n",
    "                  \"W2\" : W2,\n",
    "                  \"b2\" : b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5bce2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1 # n_h, m\n",
    "    A1 = np.maximum(0, Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2 # n_y, m\n",
    "    A2 = Z2\n",
    "\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8820f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y):\n",
    "\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    MSE = (1/m)*np.dot((A2-Y), (A2-Y).T)\n",
    "    cost = np.squeeze(MSE)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8eb0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "\n",
    "    A1 = cache[\"A1\"]\n",
    "    Z1 = cache[\"Z1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "\n",
    "    dZ2 = (2/m)*(A2-Y)\n",
    "    dW2 = (2/m)*np.dot((A2-Y), A1.T)\n",
    "    db2 = (2/m)*np.sum((A2-Y),axis=1, keepdims=True)\n",
    "    dZ1 = (2/m)*np.dot(W2.T, A2-Y)*np.where(Z1 >= 0, 1, 0)\n",
    "    dW1 = np.dot(dZ1, X.T)\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81c093d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "    W1 = copy.deepcopy(parameters[\"W1\"])\n",
    "    b1 = copy.deepcopy(parameters[\"b1\"])\n",
    "    W2 = copy.deepcopy(parameters[\"W2\"])\n",
    "    b2 = copy.deepcopy(parameters[\"b2\"])\n",
    "\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "\n",
    "    W1 -= learning_rate*dW1\n",
    "    b1 -= learning_rate*db1\n",
    "    W2 -= learning_rate*dW2\n",
    "    b2 -= learning_rate*db2\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e249cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise(X, Y, n_h, num_iterations):\n",
    "    np.random.seed(3)\n",
    "\n",
    "    n_x = layer_sizes(X, Y, n_h)[0]\n",
    "    n_y = layer_sizes(X, Y, n_h)[2]\n",
    "\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        cost = compute_cost(A2, Y)\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    "        parameters = update_parameters(parameters, grads, 0.01)\n",
    "\n",
    "        if i%750 == 0:\n",
    "            print(f\"the error after {i} iterations = {cost}\")\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d4efd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ef1f076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the error after 0 iterations = 211.63052197734123\n",
      "the error after 750 iterations = 0.5521634144214619\n",
      "the error after 1500 iterations = 0.4520530325477524\n",
      "the error after 2250 iterations = 0.41322055743940617\n",
      "the error after 3000 iterations = 0.39165545943143004\n",
      "the error after 3750 iterations = 0.3822945033267468\n",
      "the error after 4500 iterations = 0.3758989491284076\n",
      "the error after 5250 iterations = 0.3705737209042003\n",
      "Error for red wine train 0.365636638367511\n",
      "Error for red wine test 0.3871497455873727\n",
      "the error after 0 iterations = 149.21024618513127\n",
      "the error after 750 iterations = 0.624382659677012\n",
      "the error after 1500 iterations = 0.5376495549262699\n",
      "the error after 2250 iterations = 0.5158668625304956\n",
      "the error after 3000 iterations = 0.5083542780398159\n",
      "the error after 3750 iterations = 0.5038778510871976\n",
      "the error after 4500 iterations = 0.5008251900610724\n",
      "the error after 5250 iterations = 0.4984726049174764\n",
      "Error for white wine train 0.49638452539951666\n",
      "Error for white wine test 0.5120355805280622\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "df1 = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    df1.drop(columns=[\"quality\"]).values, df1[\"quality\"].values, \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train1 = scaler.fit_transform(X_train1)  \n",
    "X_test1 = scaler.transform(X_test1)    \n",
    "\n",
    "X_train1 = X_train1.T\n",
    "X_test1 = X_test1.T\n",
    "y_train1 = y_train1.reshape(-1,1).T\n",
    "y_test1 = y_test1.reshape(-1,1).T\n",
    "\n",
    "parameters = optimise(X_train1, y_train1, 32, 6000)\n",
    "predictions = predict(parameters, X_train1)\n",
    "MSE = np.mean((predictions-y_train1)**2)\n",
    "print(f\"Error for red wine train {MSE}\")\n",
    "predictions = predict(parameters, X_test1)\n",
    "MSE = np.mean((predictions-y_test1)**2)\n",
    "print(f\"Error for red wine test {MSE}\")\n",
    "\n",
    "\n",
    "df2 = pd.read_csv(\"winequality-white.csv\", sep=\";\")\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    df2.drop(columns=[\"quality\"]).values, df2[\"quality\"].values, \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train2 = scaler.fit_transform(X_train2)  \n",
    "X_test2 = scaler.transform(X_test2)        \n",
    "\n",
    "X_train2 = X_train2.T\n",
    "X_test2 = X_test2.T\n",
    "y_train2 = y_train2.reshape(-1,1).T\n",
    "y_test2 = y_test2.reshape(-1,1).T\n",
    "\n",
    "parameters = optimise(X_train2, y_train2, 32, 6000)\n",
    "predictions = predict(parameters, X_train2)\n",
    "MSE = np.mean((predictions-y_train2)**2)\n",
    "print(f\"Error for white wine train {MSE}\")\n",
    "predictions = predict(parameters, X_test2)\n",
    "MSE = np.mean((predictions-y_test2)**2)\n",
    "print(f\"Error for white wine test {MSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8032847d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
